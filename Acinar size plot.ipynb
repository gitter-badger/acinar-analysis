{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alveoli and acinar size\n",
    "This document is used to plot the acinar volumes and stereological counts for the alveolar manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data and set up notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import pandas\n",
    "import seaborn\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    \"\"\"\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and http://stackoverflow.com/a/18283905/323100\n",
    "    \"\"\"\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git', '--git-dir', os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse', '--short', '--verify', 'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are working with version 3f03192 of the analyis notebook\n"
     ]
    }
   ],
   "source": [
    "the_current_git_hash = get_git_hash()\n",
    "print('We are working with version %s of the analyis notebook' % the_current_git_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest') # Display all images in b&w\n",
    "plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the 'Count' data from Eveline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data from this folder\n",
    "RootPath = '/run/user/1000/gvfs/smb-share:server=nas.ana.unibe.ch,share=gruppe_schittny/Data/doc/David/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of *all* excel files that Eveline exported from the STEPanizer\n",
    "# Based on https://stackoverflow.com/a/14798263\n",
    "StepanizerFiles = sorted(glob.glob(os.path.join(RootPath, 'Eveline', '**/*.xls'), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate an empty dataframe where we save the counts\n",
    "Counts = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the filename into the dataframe\n",
    "Counts = pandas.DataFrame({'Location': StepanizerFiles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Grab relevant data from filenames\n",
    "# for f in StepanizerFiles:\n",
    "#     print('Animal', os.path.basename(f).split('_R108C')[1].split('mrg-')[0][:3])\n",
    "#     print('Day', os.path.basename(f).split('_R108C')[1].split('mrg-')[0][:2])\n",
    "#     print('Acinus', os.path.basename(f).split('acinus')[1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counts = pandas.DataFrame({'Location_Counts': StepanizerFiles})\n",
    "Counts['Filename_Counts'] = [os.path.basename(f) for f in StepanizerFiles]\n",
    "Counts['Animal'] = [os.path.basename(f).split('_R108C')[1].split('mrg-')[0][:3] for f in StepanizerFiles]\n",
    "Counts['Day'] = [int(os.path.basename(f).split('_R108C')[1].split('mrg-')[0][:2]) for f in StepanizerFiles]\n",
    "Counts['Acinus'] = [int(os.path.basename(f).split('acinus')[1].split('_')[0]) for f in StepanizerFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nr=16\n",
    "# tmp=pandas.read_csv(StepanizerFiles[nr], nrows=13, delimiter='\\t')\n",
    "# # https://stackoverflow.com/a/31814158\n",
    "# print('Eveline made', tmp['Total'][9], 'counts for', os.path.basename(StepanizerFiles[nr]))\n",
    "# tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5fb7f619e764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Counts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStepanizerFiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5fb7f619e764>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Counts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStepanizerFiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:6175)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header (pandas/_libs/parsers.c:9801)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Counts['Counts'] = [int(pandas.read_csv(f, nrows=13, delimiter='\\t')['Total'][10]) for f in StepanizerFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For D60, Eveline counted only half of the images, we thus double the counts for this day.\n",
    "Counts.loc[Counts.Day == 60, 'Counts'] = 2*Counts['Counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have %s acini which Eveline assessed with the STEPanizer' % len(Counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a quick overview of the data\n",
    "Counts.groupby(by=['Day', 'Animal'])['Counts'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set ourselves a palette, based on the individual unique sample names\n",
    "# The dictionary palette setting is based on the comments in https://stackoverflow.com/q/36554075/323100\n",
    "ourcolors=seaborn.color_palette('deep', len(pandas.unique(Counts.Animal)))\n",
    "ourpalette = {animal:ourcolors[c] for c, animal in enumerate(pandas.unique(Counts.Animal))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set indivdual measurement color (in dataframe)\n",
    "Counts['Color'] = [None] * len(Counts)\n",
    "for c,animal in enumerate(Counts.Animal):\n",
    "    for d,i in enumerate(pandas.unique(Counts.Animal)):\n",
    "        if animal == i:\n",
    "            Counts.set_value(c, 'Color', ourcolors[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.palplot(ourcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.violinplot(data=Counts, x='Day', y='Counts', cut=0, scale='count',\n",
    "               palette=seaborn.color_palette('deep', len(pandas.unique(Counts.Day))))\n",
    "seaborn.swarmplot(data=Counts, x='Day', y='Counts', split=False, linewidth=1,\n",
    "              palette=seaborn.color_palette('deep', len(pandas.unique(Counts.Day))))\n",
    "plt.title('All counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,d in enumerate(pandas.unique(Counts.Day)):\n",
    "    plt.subplot(1,len(pandas.unique(Counts.Day)),c+1)\n",
    "    bxplt = seaborn.violinplot(data=Counts.loc[Counts.Day == d], x='Day', y='Counts',\n",
    "                           hue='Animal', palette=ourpalette, cut=0, inner='box')\n",
    "    swrmplt = seaborn.swarmplot(data=Counts.loc[Counts.Day == d], x='Day', y='Counts', hue='Animal',\n",
    "                            split=True, linewidth=1, palette=ourpalette)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.ylim([0,1.1*Counts.Counts.max()])\n",
    "    bxplt.legend(handles[:len(handles)//2], labels[:len(labels)//2])\n",
    "plt.suptitle('Counts, split per animal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the volume data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First directly from `anatera4`, where I originally exported the DICOM files from MeVisLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terastation = '/run/user/1000/gvfs/smb-share:server=anatera4,share=share/SLS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "# tic=timeit.default_timer()\n",
    "# # Do Stuff\n",
    "# toc=timeit.default_timer()\n",
    "# toc - tic #elapsed time in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of *all* DICOM files that I exported aeons ago\n",
    "# Based on https://stackoverflow.com/a/14798263\n",
    "print('We scan %s for \"R108*.dcm\" files' % terastation)\n",
    "tic=timeit.default_timer()\n",
    "AcinarVolumeFiles= sorted(glob.glob(os.path.join(terastation, '**/R108*.dcm'), recursive=True))\n",
    "toc=timeit.default_timer()\n",
    "print('We found %s DICOM files in %s minutes' % (len(AcinarVolumeFiles), round(float((toc - tic)/60.),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate an empty dataframe where we save the volumes\n",
    "VolumesFromDisk = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sorted(AcinarVolumeFiles_glob)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the filename into the dataframe\n",
    "VolumesFromDisk = pandas.DataFrame({'Location': AcinarVolumeFiles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Grab relevant data from filenames\n",
    "# for f in AcinarVolumeFiles_glob:\n",
    "#     print(os.path.basename(f))\n",
    "#     print('Animal', os.path.basename(f).split('R108C')[1].split('mrg.')[0][:-2])\n",
    "#     print('Day', os.path.basename(f).split('R108C')[1].split('mrg')[0][:2])\n",
    "#     print('Acinus', os.path.basename(f).split('.acinus')[1].split('.volume')[0])\n",
    "#     print('Volume', os.path.basename(f).split('.volume')[1].split('.pixelsize')[0])\n",
    "#     print('Scantime', os.path.dirname(f).split('/SLS/')[1].split('/')[0])\n",
    "#     print(80*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Some names (see output of this cell) derive from the R108C$Day$$Animal$ scheme.\n",
    "# # We catch them with the intricate .split() in the cells below...\n",
    "# for i in VolumesFromDisk.File:\n",
    "#     if len(i.split('mrg')[0][len('R108C'):-2]) >3:\n",
    "#         tmp.append(i.split('mrg')[0][len('R108C'):-2])\n",
    "# for i in pandas.unique(tmp):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VolumesFromDisk = pandas.DataFrame({'Location': AcinarVolumeFiles_glob})\n",
    "VolumesFromDisk['File'] = [os.path.basename(f) for f in AcinarVolumeFiles_glob]\n",
    "VolumesFromDisk['Animal'] = [os.path.basename(f).split('mrg')[0][len('R108C'):len('R108C')+3]\n",
    "                             for f in AcinarVolumeFiles_glob]\n",
    "VolumesFromDisk['Scantime'] = [os.path.dirname(f).split('/SLS/')[1].split('/')[0]\n",
    "                          for f in AcinarVolumeFiles_glob]\n",
    "VolumesFromDisk['Day'] = [int(os.path.basename(f).split('mrg')[0][len('R108C'):len('R108C')+2])\n",
    "                          for f in AcinarVolumeFiles_glob]\n",
    "VolumesFromDisk['Acinus'] = [int(os.path.basename(f).split('.acinus')[1].split('.volume')[0])\n",
    "                             for f in AcinarVolumeFiles_glob]\n",
    "VolumesFromDisk['Volume'] = [float(os.path.basename(f).split('.volume')[1].split('.pixelsize')[0])\n",
    "                             for f in AcinarVolumeFiles_glob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have %s acini where we got the volumes' % len(VolumesFromDisk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VolumesFromDisk.groupby(by=['Day', 'Animal'])['Volume'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update palette, since we might have more animals than what we had above in cell 19\n",
    "ourcolors=seaborn.color_palette('deep', len(pandas.unique(VolumesFromDisk.Animal)))\n",
    "ourpalette = {animal:ourcolors[c] for c, animal in enumerate(sorted(pandas.unique(VolumesFromDisk.Animal)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for c,d in enumerate(sorted(pandas.unique(VolumesFromDisk.Day))):\n",
    "#     print(d)\n",
    "#     print(pandas.unique(VolumesFromDisk.loc[VolumesFromDisk.Day == d]['Animal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,d in enumerate(sorted(pandas.unique(VolumesFromDisk.Day))):\n",
    "    plt.subplot(1,len(pandas.unique(VolumesFromDisk.Day)),c+1)\n",
    "    bxplt = seaborn.violinplot(data=VolumesFromDisk.loc[VolumesFromDisk.Day == d], x='Day', y='Volume',\n",
    "                               hue='Animal',\n",
    "                               # Because the animals are preferentially sorted on the beamtime name, we have\n",
    "                               # to jump through the hoop below and sort the hues on the 'Animal' in addition\n",
    "                               # to what we did for Evelines counts where all the data is in *one* folder\n",
    "                               # Just comment the line to see the difference (a correct plot, but ugly sort :)\n",
    "                               hue_order=sorted(pandas.unique(VolumesFromDisk.loc[VolumesFromDisk.Day == d]['Animal'])),\n",
    "                               palette=ourpalette, cut=0, inner='box')\n",
    "    swrmplt = seaborn.swarmplot(data=VolumesFromDisk.loc[VolumesFromDisk.Day == d], x='Day', y='Volume',\n",
    "                                hue='Animal',\n",
    "                                hue_order=sorted(pandas.unique(VolumesFromDisk.loc[VolumesFromDisk.Day == d]['Animal'])),\n",
    "                                split=True, linewidth=1, palette=ourpalette)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.ylim([0,1.1*VolumesFromDisk.Volume.max()])\n",
    "    bxplt.legend(handles[:len(handles)//2], labels[:len(labels)//2])\n",
    "plt.suptitle('Volumes, read from disk. Split per animal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we 'just' have to concatenate the two dataframes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes: http://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "# This seems to discard all entries that are *not* found in both df's\n",
    "print('\\n\\nTODO: confirm values by randomly sampling some file names and Count XLS sheets\\n\\n')\n",
    "Merged = pandas.merge(Counts, VolumesFromDisk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Merged['CpV'] = Merged['Counts']/Merged['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublecheck\n",
    "import numpy.random\n",
    "for i in range(3):\n",
    "    print(80*'-')\n",
    "    print(Merged.loc[numpy.random.randint(len(Merged))].to_dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,d in enumerate(sorted(pandas.unique(Merged.Day))):\n",
    "    plt.subplot(1,len(pandas.unique(Merged.Day)),c+1)\n",
    "    bxplt = seaborn.violinplot(data=Merged.loc[Merged.Day == d], x='Day', y='CpV',\n",
    "                               hue='Animal',\n",
    "                               hue_order=sorted(pandas.unique(Merged.loc[Merged.Day == d]['Animal'])),\n",
    "                               palette=ourpalette, cut=0, inner='box')\n",
    "    swrmplt = seaborn.swarmplot(data=Merged.loc[Merged.Day == d], x='Day', y='CpV',\n",
    "                                hue='Animal',\n",
    "                                hue_order=sorted(pandas.unique(Merged.loc[Merged.Day == d]['Animal'])),\n",
    "                                split=True, linewidth=1, palette=ourpalette)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.ylim([0,1.1*Merged.CpV.max()])\n",
    "    bxplt.legend(handles[:len(handles)//2], labels[:len(labels)//2])\n",
    "plt.suptitle('Count sper volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "The stuff below is from an old version of the [Jupyter notebook](http://jupyter.org), please disregard it for the moment...\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Johannes also compiled a list of the volumes and saved them in an XLS file.\n",
    "Let's load that, so that we can compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Volume data from Johannes' XLS-sheet\n",
    "Volumes = pandas.read_excel(pandas.ExcelFile(os.path.join(RootPath, 'JCS', 'Acinarvol-JCS171122.xlsx'), sheet='Acinarvol'),\n",
    "                        skiprows=19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed' colums\n",
    "Volumes.drop(list(Volumes.filter(regex='Unnamed')), axis=1, inplace=True)\n",
    "# Drop the unnecessary columns\n",
    "Volumes.drop('4.5', axis=1, inplace=True)\n",
    "Volumes.drop('60.4', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data looks like that\n",
    "Volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the column names to something meaningful\n",
    "# Use some `regular expression` https://www.regular-expressions.info/anchors.html\n",
    "Volumes.rename(columns=lambda x: re.sub('^4', '04', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub('\\.1$', 'B', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub('\\.2$', 'C', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub('\\.3$', 'D', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub('\\.4$', 'E', str(x)), inplace=True)\n",
    "# https://stackoverflow.com/a/31697086/323100\n",
    "Volumes.rename(columns=lambda x: re.sub(r'\\b04\\b', '04A', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub(r'\\b10\\b', '10A', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub(r'\\b21\\b', '21A', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub(r'\\b36\\b', '36A', str(x)), inplace=True)\n",
    "Volumes.rename(columns=lambda x: re.sub(r'\\b60\\b', '60A', str(x)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a color palette to distinguish between postnatal days\n",
    "daycolor = [None] * len(Volumes.columns.values)\n",
    "day = [None] * len(Volumes.columns.values)\n",
    "for c,i in enumerate(Volumes.columns.values):\n",
    "    if int(i[:-1])==4:\n",
    "        day[c] = '04'\n",
    "        daycolor[c] = seaborn.color_palette()[0]\n",
    "    elif int(i[:-1])==10:\n",
    "        day[c] = '10'\n",
    "        daycolor[c] = seaborn.color_palette()[1]\n",
    "    elif int(i[:-1])==21:\n",
    "        day[c] = '21'\n",
    "        daycolor[c] = seaborn.color_palette()[2]\n",
    "    elif int(i[:-1])==36:\n",
    "        day[c] = '36'\n",
    "        daycolor[c] = seaborn.color_palette()[3]\n",
    "    else:\n",
    "        day[c] = '60'\n",
    "        daycolor[c] = seaborn.color_palette()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the volume data\n",
    "seaborn.violinplot(data=Volumes, cut=0, width=1, scale='count', palette=daycolor)\n",
    "seaborn.swarmplot(data=Volumes, alpha=0.618, linewidth=1, palette=daycolor)\n",
    "plt.title(\"Volumes from Johannes' XLS file\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Volumes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridges\n",
    "Eveline also counted the [*bridges*](http://www.stereology.info/connectivity/) in the datasets.\n",
    "Tiziana cleaned this data up and saved it to an Excel file (`acini merge.xlsx`).\n",
    "We've made the file a bit more consistent (removing empty columns and rows, naming columns consistently, etc.) and work with this file (`acini merge_edit.xlsx`) below.\n",
    "\n",
    "Below we load this file and calculate the number of acini according to [our paper for day 60](http://jap.physiology.org/content/115/9/1379).\n",
    "The calculation for this paper was done in [MATLAB](https://www.mathworks.com/products/matlab.html)/[R](https://www.r-project.org/), nowadays I'm more handy with Python...\n",
    "\n",
    "I was not able to find the original calculation script on the ana.unibe.ch network drives, but I seem to have saved a copy of the calculation and insertion to the [LaTeX](https://www.latex-project.org/) manuscript file in a *very* old [GitHub repository here](https://github.com/habi/AcinusPaperCode/blob/master/AcinarSize/ReadVolumeSurfaceAndAlveaolarNumber.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pandas.ExcelFile('acini merge_edit.xlsx')\n",
    "print('The excel file contains the sheets:', end=' ')\n",
    "for i in DataFile.sheet_names:\n",
    "    print(i,end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the single sheets of the XLS file each into a dataframe\n",
    "D04 = DataFile.parse(DataFile.sheet_names[0])\n",
    "D10 = DataFile.parse(DataFile.sheet_names[1])\n",
    "D21 = DataFile.parse(DataFile.sheet_names[2])\n",
    "D60 = DataFile.parse(DataFile.sheet_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename 'Counts.' to 'Counts..0' (we use the Counts. counter later on)\n",
    "D04.rename(columns={'Counts':'Counts.0'}, inplace=True)\n",
    "D10.rename(columns={'Counts':'Counts.0'}, inplace=True)\n",
    "D21.rename(columns={'Counts':'Counts.0'}, inplace=True)\n",
    "D60.rename(columns={'Counts':'Counts.0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For D60, Eveline counted only half of the images, we thus double the counts for this day.\n",
    "print('Original D60')\n",
    "print(D60.head())\n",
    "for i in range(3):\n",
    "    D60.iloc[:,2*i+1] =  D60.iloc[:,2*i+1] * 2\n",
    "print('\\nDouble the counts for D60')    \n",
    "print(D60.head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the data as [notched](https://en.wikipedia.org/wiki/Box_plot#Variations) boxplots.\n",
    "The notches give a rough guide to the significance of difference of medians; if the notches of two boxes do not overlap, this offers evidence of a statistically significant difference between the medians.\n",
    "On top of the boxplots we do a jittered scatterplot of the datapoints, to see the distribution of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the 'counts' from Eveline\n",
    "upper_limit=1350\n",
    "plt.subplot(141)\n",
    "seaborn.boxplot(data=D04.iloc[:,[1,3,5]], color=seaborn.color_palette()[0], notch=True)\n",
    "seaborn.swarmplot(data=D04.iloc[:,[1,3,5]], color=seaborn.color_palette()[0], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D04)[0], list(D04)[2], list(D04)[4]])\n",
    "plt.title('Counts. D04')\n",
    "plt.subplot(142)\n",
    "seaborn.boxplot(data=D10.iloc[:,[1,3,5]], color=seaborn.color_palette()[1], notch=True)\n",
    "seaborn.swarmplot(data=D10.iloc[:,[1,3,5]], color=seaborn.color_palette()[1], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D10)[0], list(D10)[2], list(D10)[4]])\n",
    "plt.title('Counts. D10')\n",
    "plt.subplot(143)\n",
    "seaborn.boxplot(data=D21.iloc[:,[1,3,5]], color=seaborn.color_palette()[2], notch=True)\n",
    "seaborn.swarmplot(data=D21.iloc[:,[1,3,5]], color=seaborn.color_palette()[2], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D21)[0], list(D21)[2], list(D21)[4]])\n",
    "plt.title('Counts. D21')\n",
    "plt.subplot(144)\n",
    "seaborn.boxplot(data=D60.iloc[:,[1,3,5]], color=seaborn.color_palette()[4], notch=True)\n",
    "seaborn.swarmplot(data=D60.iloc[:,[1,3,5]], color=seaborn.color_palette()[4], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D60)[0], list(D60)[2], list(D60)[4]])\n",
    "plt.title('Counts. D60')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide the volume by the counts, add this as a column to the dataframes\n",
    "for i in range(3):\n",
    "    D04['Ratio.%s' % i] =  D04.iloc[:,2*i+1]/D04.iloc[:,2*i]\n",
    "    D10['Ratio.%s' % i] =  D10.iloc[:,2*i+1]/D10.iloc[:,2*i]\n",
    "    D21['Ratio.%s' % i] =  D21.iloc[:,2*i+1]/D21.iloc[:,2*i]\n",
    "    D60['Ratio.%s' % i] =  D60.iloc[:,2*i+1]/D60.iloc[:,2*i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D60.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 'count per volume' ratio\n",
    "upper_limit = 9e3\n",
    "plt.subplot(141)\n",
    "seaborn.boxplot(data=D04.iloc[:,[6,7,8]], color=seaborn.color_palette()[0], notch=True)\n",
    "seaborn.swarmplot(data=D04.iloc[:,[6,7,8]], color=seaborn.color_palette()[0], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D04)[0], list(D04)[2], list(D04)[4]])\n",
    "plt.title('Counts. per volume D04')\n",
    "plt.subplot(142)\n",
    "seaborn.boxplot(data=D10.iloc[:,[6,7,8]], color=seaborn.color_palette()[1], notch=True)\n",
    "seaborn.swarmplot(data=D10.iloc[:,[6,7,8]], color=seaborn.color_palette()[1], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D10)[0], list(D10)[2], list(D10)[4]])\n",
    "plt.title('Counts. per volume D10')\n",
    "plt.subplot(143)\n",
    "seaborn.boxplot(data=D21.iloc[:,[6,7,8]], color=seaborn.color_palette()[2], notch=True)\n",
    "seaborn.swarmplot(data=D21.iloc[:,[6,7,8]], color=seaborn.color_palette()[2], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D21)[0], list(D21)[2], list(D21)[4]])\n",
    "plt.title('Counts. per volume D21')\n",
    "plt.subplot(144)\n",
    "seaborn.boxplot(data=D60.iloc[:,[6,7,8]], color=seaborn.color_palette()[4], notch=True)\n",
    "seaborn.swarmplot(data=D60.iloc[:,[6,7,8]], color=seaborn.color_palette()[4], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0,upper_limit])\n",
    "plt.xticks(range(3), [list(D60)[0], list(D60)[2], list(D60)[4]])\n",
    "plt.title('Counts. per volume D60')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup (copied verbatim from (ReadVolumeSurfaceAndAlveaolarNumber.py)\n",
    "TOMCATVoxelSize = 1.48\n",
    "SliceNumber = 10  # every $SliceNumber slice was exported, thus needed for scaling \n",
    "DisectorThickness = 5 # slices\n",
    "ShrinkageFactor = 0.61 # Volume-Shrinkage-Factor = 61% with STD=5, calculated by Sébastien: Volume TOMCAT / Waterdisplacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hsiah2010 p. 407:\n",
    "# Counting the number of entrance rings in paired sections by the disector\n",
    "# technique allows estimation of total number of alveoli in the lung N(a,L) (112, 113).\n",
    "# N(a,L) is the product of the number of alveolar openings per unit parenchyma\n",
    "# volume (Sn/Vp) with the volume density of parenchyma per unit lung volume VV(p,L)\n",
    "# and the absolute lung volume:\n",
    "# N(a,L,) = (Sn/Vp) * VV(p,L) * V(L) (Formula 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the 'Area_Vol' from the STEPanizer-Files, it's in the line where we have 'a(p)'\n",
    "# Area_Vol = double(line[1])*STEPanizerPixelSize_Vol**2\n",
    "# We need the STEPanizer pixel size, it's in the line where we have 'Pixel size'\n",
    "STEPanizerPixelSize_Vol = 3.\n",
    "print('GET CORRECT AREA_VOL')\n",
    "Area_Vol = 2. * STEPanizerPixelSize_Vol**2\n",
    "AcinusTestPoints = 15\n",
    "\n",
    "\n",
    "# Volume = AcinusTestPoints * Area_Vol * STEPanizerPixelSize_Vol * SliceNumber * TOMCATVoxelSize\t\t\n",
    "AcinarVolumeSTEPanizer = (((AcinusTestPoints *\n",
    "                            Area_Vol *\n",
    "                            STEPanizerPixelSize_Vol *\n",
    "                            SliceNumber *\n",
    "                            TOMCATVoxelSize ) /\n",
    "                           ShrinkageFactor ) / 1e12 ) # scaling volume to cm^3: http://is.gd/wbZ81O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the 'Area_Alveoli' from the STEPanizer-Files, it's in the line where we have 'a(p)'\n",
    "# We need the STEPanizer pixel size, it's in the line where we have 'Pixel size'\n",
    "STEPanizerPixelSize_Alveoli = 3.\n",
    "print('GET CORRECT AREA_VOL')\n",
    "Area_Alveoli = 2. * STEPanizerPixelSize_Alveoli**2\n",
    "Counts = 15\n",
    "# Counts. are *all* counted bridges, (from a to b and from b to a). According \n",
    "# to Stefan, we thus have to double the disector volume. This is then the \n",
    "# volume density of the counts in said acinus.\n",
    "\n",
    "# From Evelyne we get the Counts per volume, see above.\n",
    "# These values go into the 'AlveolarFraction'\n",
    "# This is then multiplied by the volume of the acinus to get the number of alveoli in each acinus.\n",
    "# The volume is taken from the 'allcounts' or 'eveline' dataframes at the beginning.\n",
    "\n",
    "# AlveolarFraction = Counts / ( ( Area_Alveoli * ( DisectorThickness / ShrinkageFactor ) ) * 2 ) * 1e12 # Counts./cm^3\n",
    "# DisectorThickness = um, Area_Alveoli = um^2 -> 10^12 um^3 = 1 cm^3: http://is.gd/Cr6kUL\n",
    "for i in range(3):\n",
    "    D04['Alveolar fraction.%s' % i] = D04['Counts.%s' % i] / ((Area_Alveoli * (DisectorThickness / ShrinkageFactor)) * 2) * 1e12 # Counts/cm^3\n",
    "    D10['Alveolar fraction.%s' % i] = D04['Counts.%s' % i] / ((Area_Alveoli * (DisectorThickness / ShrinkageFactor)) * 2) * 1e12 # Counts/cm^3\n",
    "    D21['Alveolar fraction.%s' % i] = D04['Counts.%s' % i] / ((Area_Alveoli * (DisectorThickness / ShrinkageFactor)) * 2) * 1e12 # Counts/cm^3\n",
    "    D60['Alveolar fraction.%s' % i] = D04['Counts.%s' % i] / ((Area_Alveoli * (DisectorThickness / ShrinkageFactor)) * 2) * 1e12 # Counts/cm^3\n",
    "\n",
    "# NumberOfAlveoli = AlveolarFraction * AcinarVolumeSTEPanizer\n",
    "for i in range(3):\n",
    "    D04['NumAlveoli.%s' % i] = D04.iloc[:,2*i] * D04['Alveolar fraction.%s' % i]\n",
    "    D10['NumAlveoli.%s' % i] = D10.iloc[:,2*i] * D10['Alveolar fraction.%s' % i]\n",
    "    D21['NumAlveoli.%s' % i] = D21.iloc[:,2*i] * D21['Alveolar fraction.%s' % i]\n",
    "    D60['NumAlveoli.%s' % i] = D60.iloc[:,2*i] * D60['Alveolar fraction.%s' % i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = 9e10\n",
    "plt.subplot(141)\n",
    "seaborn.boxplot(data=D04.iloc[:,-3:], color=seaborn.color_palette()[0], notch=True)\n",
    "seaborn.swarmplot(data=D04.iloc[:,-3:], color=seaborn.color_palette()[0], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0, ymax])\n",
    "plt.xticks(range(3), [list(D04)[0], list(D04)[2], list(D04)[4]])\n",
    "plt.title('Day 4')\n",
    "plt.subplot(142)\n",
    "seaborn.boxplot(data=D10.iloc[:,-3:], color=seaborn.color_palette()[1], notch=True)\n",
    "seaborn.swarmplot(data=D10.iloc[:,-3:], color=seaborn.color_palette()[1], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0, ymax])\n",
    "plt.xticks(range(3), [list(D10)[0], list(D10)[2], list(D10)[4]])\n",
    "plt.title('Day 10')\n",
    "plt.subplot(143)\n",
    "seaborn.boxplot(data=D21.iloc[:,-3:], color=seaborn.color_palette()[2], notch=True)\n",
    "seaborn.swarmplot(data=D21.iloc[:,-3:], color=seaborn.color_palette()[2], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0, ymax])\n",
    "plt.xticks(range(3), [list(D21)[0], list(D21)[2], list(D21)[4]])\n",
    "plt.title('Day 21')\n",
    "plt.subplot(144)\n",
    "seaborn.boxplot(data=D60.iloc[:,-3:], color=seaborn.color_palette()[4], notch=True)\n",
    "seaborn.swarmplot(data=D60.iloc[:,-3:], color=seaborn.color_palette()[4], size=10, facecolor='k', linewidth=1, alpha=0.5)\n",
    "plt.ylim([0, ymax])\n",
    "plt.xticks(range(3), [list(D60)[0], list(D60)[2], list(D60)[4]])\n",
    "plt.title('Day 60')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
